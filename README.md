# SCM-DL: Talent Identification using Machine Learning

A modular Python implementation for talent identification using Supply Chain Management combined with Deep Learning (SCM-DL).

## ğŸ“‹ Overview

This project implements a machine learning pipeline for talent identification that achieves **94-97% accuracy** on the TID dataset. The codebase has been refactored from a monolithic script into a clean, modular package structure.

## ğŸ—ï¸ Project Structure

```
SRC/
â”œâ”€â”€ main.py                     # Entry point - orchestrates the entire pipeline
â”œâ”€â”€ config.py                   # Centralized configuration and hyperparameters
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ seed.py                 # Random seed management for reproducibility
â”‚   â””â”€â”€ io_helpers.py           # File/directory utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loader.py               # Dataset loading and train/test splitting
â”‚   â””â”€â”€ preprocessing.py        # Feature normalization (MinMaxScaler)
â”œâ”€â”€ feature_selection/
â”‚   â”œâ”€â”€ statistical.py          # SelectKBest (chi2, ANOVA, Mutual Info)
â”‚   â”œâ”€â”€ lasso_selector.py       # Lasso regression-based selection
â”‚   â”œâ”€â”€ boruta_selector.py      # Boruta with Random Forest
â”‚   â””â”€â”€ rfe_selector.py         # RFE with RFC, ETC, SVC, DTC
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py              # Confusion matrix, sensitivity, specificity
â”‚   â””â”€â”€ visualization.py        # Feature ranking plots, class distribution
â”œâ”€â”€ classifiers/
â”‚   â””â”€â”€ factory.py              # Model creation (sklearn + SCM_DL)
â””â”€â”€ models/
    â”œâ”€â”€ SCM_DL_BaseModel.py     # Custom deep learning architecture
    â””â”€â”€ CinsConMat.py           # ROC and precision/recall calculations
```

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install tensorflow numpy pandas scikit-learn matplotlib seaborn boruta
```

### Running the Pipeline

```bash
cd SRC
python main.py <num_features_to_select>
```

**Example:**
```bash
python main.py 6
```

This runs the complete pipeline:
1. Loads the TID dataset
2. Applies 8 feature selection methods
3. Trains 5 classifiers on each feature subset
4. Saves results, confusion matrices, and ROC plots

## âš™ï¸ Configuration

All hyperparameters are centralized in `config.py`:

| Parameter | Value | Description |
|-----------|-------|-------------|
| `SEED` | 42 | Random seed for reproducibility |
| `TEST_SIZE` | 0.2 | Train/test split ratio |
| `epochs` | 200 | Training epochs for DL models |
| `batch_size` | 16 | Batch size for training |
| `learning_rate` | 0.00001 | Learning rate for Adam optimizer |
| `layer_units` | [[128,128,64]Ã—3] | SCM_DL network architecture |

## ğŸ“Š Feature Selection Methods

| Method | Type | Description |
|--------|------|-------------|
| SelectKBest (chi2) | Statistical | Chi-squared test |
| SelectKBest (ANOVA) | Statistical | F-value (ANOVA) |
| SelectKBest (MI) | Statistical | Mutual Information |
| Lasso | Regularization | L1 penalty coefficients |
| Boruta | Ensemble | Random Forest wrapper |
| RFE-RFC | Recursive | Random Forest Classifier |
| RFE-ETC | Recursive | Extra Trees Classifier |
| RFE-SVC | Recursive | Support Vector Classifier |
| RFE-DTC | Recursive | Decision Tree Classifier |

## ğŸ¤– Classifiers

- **RFC** - Random Forest Classifier
- **ETC** - Extra Trees Classifier
- **SVC** - Support Vector Classifier (linear kernel)
- **DTC** - Decision Tree Classifier
- **SCM_DL** - Custom multi-branch deep learning model

## ğŸ“ Output Structure

After running, results are saved to `Results_<num_features>/`:

```
Results_6/
â”œâ”€â”€ Figures26_01_25_1640/          # Feature ranking plots
â”œâ”€â”€ Confusions26_01_25_1640/       # Confusion matrices and ROC curves
â”œâ”€â”€ FE_Results_26_01_25_1640.txt   # Detailed results log
â””â”€â”€ ResultDF_6_Features_*.csv      # Summary DataFrame
```

## ğŸ“ˆ Expected Accuracy

With 6 selected features on the TID dataset:
- **SCM_DL**: 94-97%
- **RFC**: ~90-93%
- **ETC**: ~88-92%

## ğŸ“š References

- **Paper**: [https://dx.doi.org/10.1109/ACCESS.2025.3562551](https://dx.doi.org/10.1109/ACCESS.2025.3562551)
- **GitHub**: [https://github.com/Comvislab/TID](https://github.com/Comvislab/TID)

## Citation
If you use our work, please cite our paper:

```
- @ARTICLE{10971350,
  author={Abidin, Didem and Erdem, Muhammed G.},
  journal={IEEE Access}, 
  title={SCM-DL: Split-Combine-Merge Deep Learning Model Integrated With Feature Selection in Sports for Talent Identification}, 
  year={2025},
  volume={13},
  number={},
  pages={71148-71172},
  keywords={Sports;Adaptation models;Feature extraction;Deep learning;Artificial neural networks;Data models;Psychology;Object recognition;Motors;Random forests;Deep learning;neural networks;recursive feature selection;talent identification},
  doi={10.1109/ACCESS.2025.3562551}}
```

## ğŸ‘¤ Author

**Muhammet GÃ¶khan Erdem**
- Email: merdem@comvislab.com
- Website: [https://comvislab.com](https://comvislab.com)

## ğŸ“„ License

ComVIS Lab - All rights reserved.
